# REPORT
## ASSIGNMENT - 4

#### 1. Introduction

Message Passing Interface (MPI) is a standardized communication protocol used for parallel programming on distributed memory systems. It allows multiple processes to communicate using message passing techniques. MPI is widely used in high-performance computing because of its scalability, portability, and efficiency.
In this assignment, different MPI programs were implemented to understand point-to-point communication, collective communication, reduction operations, and performance analysis.

#### 2. Exercise 1 – Ring Communication
Objective

To implement a ring topology where each process sends a token to the next process.

Results
Processes	Final Value at Rank 0
| Processes | Final Value at Rank 0 |
| --------- | --------------------- |
| 2         | 101                   |
| 4         | 106                   |
| 8         | 128                   |

Explanation
The token starts at value 100 in process 0. Each process receives the token, adds its rank, and passes it to the next process. The last process sends the token back to process 0.


#### 3. Exercise 2 – Parallel Array Sum
Objective

To compute the sum of numbers from 1 to 100 using parallel processing.

Results
Processes	Global Sum	Average
| Processes | Global Sum | Average |
| --------- | ---------- | ------- |
| 1         | 5050       | 50.50   |
| 2         | 5050       | 50.50   |
| 4         | 5050       | 50.50   |

Explanation

The array was divided among processes using MPI_Scatter. Each process computed a local sum. MPI_Reduce combined all local sums to produce the final global sum.


#### 4. Exercise 3 – Global Maximum and Minimum
Objective

To find the global maximum and minimum values generated by all processes.

Sample Results
Processes	Global Max	Rank	Global Min	Rank
| Processes | Global Max | Rank | Global Min | Rank |
| --------- | ---------- | ---- | ---------- | ---- |
| 4         | 896        | 2    | 34         | 2    |
| 8         | 990        | 7    | 18         | 0    |

Explanation

Each process generated random numbers and calculated its local minimum and maximum. MPI_MAXLOC and MPI_MINLOC were used to determine global extreme values along with the rank of the process that generated them.


#### 5. Exercise 4 – Parallel Dot Product
Objective

To compute the dot product of two vectors in parallel.

Vector A = [1,2,3,4,5,6,7,8]
Vector B = [8,7,6,5,4,3,2,1]

Expected Result = 120

Results

| Processes | Dot Product |
| --------- | ----------- |
| 1         | 120         |
| 2         | 120         |
| 4         | 120         |
| 8         | 120         |

Explanation

The vectors were divided among processes using MPI_Scatter. Each process computed a partial dot product. MPI_Reduce was used to sum partial results into the final result.

#### 6. Performance Analysis

Execution time was measured using MPI_Wtime(). Performance metrics were calculated as follows:

Speedup:

Sp = T1 / Tp

Efficiency:

Ep = Sp / p
Sample Performance Table for Ex 4.
| Processes (p) | Time Tp (s) | Speedup Sp = T1/Tp | Efficiency Ep = Sp/p |
| ------------: | ----------: | -----------------: | -------------------: |
|             1 |    0.000041 |              1.000 |                1.000 |
|             2 |    0.000037 |              1.108 |                0.554 |
|             4 |    0.000033 |              1.242 |                0.311 |
|             8 |    0.000092 |              0.446 |                0.056 |


Graphs:


<img width="606" height="364" alt="Screenshot 2026-02-22 225403" src="https://github.com/user-attachments/assets/97b3031f-cf45-4f1c-9b3f-7bdf0c5b6345" />


<img width="595" height="346" alt="Screenshot 2026-02-22 225457" src="https://github.com/user-attachments/assets/39d37bd1-dd2d-450f-9d97-2e6597468edc" />


The observed speedup is limited due to the small problem size (N=8). As the number of processes increases, communication and synchronization overhead dominate computation time. At 8 processes, overhead exceeds computation time, resulting in reduced performance and speedup less than 1.

#### 7. Conclusion

This assignment demonstrated the use of MPI for parallel programming. Various communication methods such as point-to-point communication, scatter, reduce, and collective operations were implemented successfully. Performance analysis showed that parallel programs can reduce execution time but are limited by communication overhead and synchronization delays.
